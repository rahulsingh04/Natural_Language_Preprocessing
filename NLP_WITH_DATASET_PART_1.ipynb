{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70497414",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm \n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71fbc83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Corona_NLP_train.csv\", encoding='latin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9dfdf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data['Location OriginalTweet Sentiment'.split()]\n",
    "data.columns = [i.lower() for i in data.columns ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6750472f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "location\n",
       "London                          540\n",
       "United States                   528\n",
       "London, England                 520\n",
       "New York, NY                    395\n",
       "Washington, DC                  373\n",
       "                               ... \n",
       "Staffordshire Moorlands           1\n",
       "Kithchener ON                     1\n",
       "Tulsa, Ok                         1\n",
       "Watford, South Oxhey, Bushey      1\n",
       "i love you so much || he/him      1\n",
       "Name: count, Length: 12220, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.location.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89be5fa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>originaltweet</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>London</td>\n",
       "      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  location                                      originaltweet sentiment\n",
       "0   London  @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...   Neutral"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b09b0450",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 41157/41157 [00:01<00:00, 24800.74it/s]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def clean_text(string):\n",
    "    s = re.sub(r'https?://\\S+|www\\.\\S+', '', string)\n",
    "    s = re.sub('[^a-zA-Z0-9]',' ', s.lower())\n",
    "    return s.strip()\n",
    "\n",
    "data['corpus'] = data['originaltweet'].progress_apply(lambda x: clean_text(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b71d973",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Removing StopWords :->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c431960d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 41157/41157 [00:20<00:00, 2016.49it/s]\n"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "def txt_tokenization_and_removing_stop_words(x):\n",
    "    words = [word.lower() for word in nltk.word_tokenize(x) if word.lower() not in stop_words]\n",
    "    return words\n",
    "\n",
    "data['txt_preprocessing'] = data['corpus'].progress_apply(txt_tokenization_and_removing_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "570bd45a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>originaltweet</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>corpus</th>\n",
       "      <th>txt_preprocessing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>London</td>\n",
       "      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>menyrbie  phil gahan  chrisitv  and  and</td>\n",
       "      <td>[menyrbie, phil, gahan, chrisitv]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UK</td>\n",
       "      <td>advice Talk to your neighbours family to excha...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>advice talk to your neighbours family to excha...</td>\n",
       "      <td>[advice, talk, neighbours, family, exchange, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vagabonds</td>\n",
       "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>coronavirus australia  woolworths to give elde...</td>\n",
       "      <td>[coronavirus, australia, woolworths, give, eld...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>My food stock is not the only one which is emp...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>my food stock is not the only one which is emp...</td>\n",
       "      <td>[food, stock, one, empty, please, panic, enoug...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Me, ready to go at supermarket during the #COV...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "      <td>me  ready to go at supermarket during the  cov...</td>\n",
       "      <td>[ready, go, supermarket, covid19, outbreak, pa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    location                                      originaltweet  \\\n",
       "0     London  @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...   \n",
       "1         UK  advice Talk to your neighbours family to excha...   \n",
       "2  Vagabonds  Coronavirus Australia: Woolworths to give elde...   \n",
       "3        NaN  My food stock is not the only one which is emp...   \n",
       "4        NaN  Me, ready to go at supermarket during the #COV...   \n",
       "\n",
       "            sentiment                                             corpus  \\\n",
       "0             Neutral           menyrbie  phil gahan  chrisitv  and  and   \n",
       "1            Positive  advice talk to your neighbours family to excha...   \n",
       "2            Positive  coronavirus australia  woolworths to give elde...   \n",
       "3            Positive  my food stock is not the only one which is emp...   \n",
       "4  Extremely Negative  me  ready to go at supermarket during the  cov...   \n",
       "\n",
       "                                   txt_preprocessing  \n",
       "0                  [menyrbie, phil, gahan, chrisitv]  \n",
       "1  [advice, talk, neighbours, family, exchange, p...  \n",
       "2  [coronavirus, australia, woolworths, give, eld...  \n",
       "3  [food, stock, one, empty, please, panic, enoug...  \n",
       "4  [ready, go, supermarket, covid19, outbreak, pa...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79e78c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67183971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'histori'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = PorterStemmer()\n",
    "stemmer.stem(\"history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54844b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 41157/41157 [00:39<00:00, 1049.44it/s]\n"
     ]
    }
   ],
   "source": [
    "def PorterStemmer(x):\n",
    "    return [stemmer.stem(i) for i in x]\n",
    "data['PortStemmer'] = data['txt_preprocessing'].progress_apply(PorterStemmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7ab20b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>originaltweet</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>corpus</th>\n",
       "      <th>txt_preprocessing</th>\n",
       "      <th>PortStemmer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>London</td>\n",
       "      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>menyrbie  phil gahan  chrisitv  and  and</td>\n",
       "      <td>[menyrbie, phil, gahan, chrisitv]</td>\n",
       "      <td>[menyrbi, phil, gahan, chrisitv]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UK</td>\n",
       "      <td>advice Talk to your neighbours family to excha...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>advice talk to your neighbours family to excha...</td>\n",
       "      <td>[advice, talk, neighbours, family, exchange, p...</td>\n",
       "      <td>[advic, talk, neighbour, famili, exchang, phon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vagabonds</td>\n",
       "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>coronavirus australia  woolworths to give elde...</td>\n",
       "      <td>[coronavirus, australia, woolworths, give, eld...</td>\n",
       "      <td>[coronaviru, australia, woolworth, give, elder...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>My food stock is not the only one which is emp...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>my food stock is not the only one which is emp...</td>\n",
       "      <td>[food, stock, one, empty, please, panic, enoug...</td>\n",
       "      <td>[food, stock, one, empti, pleas, panic, enough...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Me, ready to go at supermarket during the #COV...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "      <td>me  ready to go at supermarket during the  cov...</td>\n",
       "      <td>[ready, go, supermarket, covid19, outbreak, pa...</td>\n",
       "      <td>[readi, go, supermarket, covid19, outbreak, pa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    location                                      originaltweet  \\\n",
       "0     London  @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...   \n",
       "1         UK  advice Talk to your neighbours family to excha...   \n",
       "2  Vagabonds  Coronavirus Australia: Woolworths to give elde...   \n",
       "3        NaN  My food stock is not the only one which is emp...   \n",
       "4        NaN  Me, ready to go at supermarket during the #COV...   \n",
       "\n",
       "            sentiment                                             corpus  \\\n",
       "0             Neutral           menyrbie  phil gahan  chrisitv  and  and   \n",
       "1            Positive  advice talk to your neighbours family to excha...   \n",
       "2            Positive  coronavirus australia  woolworths to give elde...   \n",
       "3            Positive  my food stock is not the only one which is emp...   \n",
       "4  Extremely Negative  me  ready to go at supermarket during the  cov...   \n",
       "\n",
       "                                   txt_preprocessing  \\\n",
       "0                  [menyrbie, phil, gahan, chrisitv]   \n",
       "1  [advice, talk, neighbours, family, exchange, p...   \n",
       "2  [coronavirus, australia, woolworths, give, eld...   \n",
       "3  [food, stock, one, empty, please, panic, enoug...   \n",
       "4  [ready, go, supermarket, covid19, outbreak, pa...   \n",
       "\n",
       "                                         PortStemmer  \n",
       "0                   [menyrbi, phil, gahan, chrisitv]  \n",
       "1  [advic, talk, neighbour, famili, exchang, phon...  \n",
       "2  [coronaviru, australia, woolworth, give, elder...  \n",
       "3  [food, stock, one, empti, pleas, panic, enough...  \n",
       "4  [readi, go, supermarket, covid19, outbreak, pa...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22220d23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'history'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatizer.lemmatize(\"history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "afded95e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>originaltweet</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>corpus</th>\n",
       "      <th>txt_preprocessing</th>\n",
       "      <th>PortStemmer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>London</td>\n",
       "      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>menyrbie  phil gahan  chrisitv  and  and</td>\n",
       "      <td>[menyrbie, phil, gahan, chrisitv]</td>\n",
       "      <td>[menyrbi, phil, gahan, chrisitv]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UK</td>\n",
       "      <td>advice Talk to your neighbours family to excha...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>advice talk to your neighbours family to excha...</td>\n",
       "      <td>[advice, talk, neighbours, family, exchange, p...</td>\n",
       "      <td>[advic, talk, neighbour, famili, exchang, phon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vagabonds</td>\n",
       "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>coronavirus australia  woolworths to give elde...</td>\n",
       "      <td>[coronavirus, australia, woolworths, give, eld...</td>\n",
       "      <td>[coronaviru, australia, woolworth, give, elder...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>My food stock is not the only one which is emp...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>my food stock is not the only one which is emp...</td>\n",
       "      <td>[food, stock, one, empty, please, panic, enoug...</td>\n",
       "      <td>[food, stock, one, empti, pleas, panic, enough...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Me, ready to go at supermarket during the #COV...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "      <td>me  ready to go at supermarket during the  cov...</td>\n",
       "      <td>[ready, go, supermarket, covid19, outbreak, pa...</td>\n",
       "      <td>[readi, go, supermarket, covid19, outbreak, pa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    location                                      originaltweet  \\\n",
       "0     London  @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...   \n",
       "1         UK  advice Talk to your neighbours family to excha...   \n",
       "2  Vagabonds  Coronavirus Australia: Woolworths to give elde...   \n",
       "3        NaN  My food stock is not the only one which is emp...   \n",
       "4        NaN  Me, ready to go at supermarket during the #COV...   \n",
       "\n",
       "            sentiment                                             corpus  \\\n",
       "0             Neutral           menyrbie  phil gahan  chrisitv  and  and   \n",
       "1            Positive  advice talk to your neighbours family to excha...   \n",
       "2            Positive  coronavirus australia  woolworths to give elde...   \n",
       "3            Positive  my food stock is not the only one which is emp...   \n",
       "4  Extremely Negative  me  ready to go at supermarket during the  cov...   \n",
       "\n",
       "                                   txt_preprocessing  \\\n",
       "0                  [menyrbie, phil, gahan, chrisitv]   \n",
       "1  [advice, talk, neighbours, family, exchange, p...   \n",
       "2  [coronavirus, australia, woolworths, give, eld...   \n",
       "3  [food, stock, one, empty, please, panic, enoug...   \n",
       "4  [ready, go, supermarket, covid19, outbreak, pa...   \n",
       "\n",
       "                                         PortStemmer  \n",
       "0                   [menyrbi, phil, gahan, chrisitv]  \n",
       "1  [advic, talk, neighbour, famili, exchang, phon...  \n",
       "2  [coronaviru, australia, woolworth, give, elder...  \n",
       "3  [food, stock, one, empti, pleas, panic, enough...  \n",
       "4  [readi, go, supermarket, covid19, outbreak, pa...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66a09851",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'jhvjhb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mjhvjhb\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'jhvjhb' is not defined"
     ]
    }
   ],
   "source": [
    "jhvjhb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2cf106a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 41157/41157 [00:08<00:00, 5049.39it/s]\n"
     ]
    }
   ],
   "source": [
    "def Lemmatizer(x):\n",
    "    return [lemmatizer.lemmatize(i) for i in x]\n",
    "data['Lemmatizer'] = data['txt_preprocessing'].progress_apply(Lemmatizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5df5b20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>originaltweet</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>corpus</th>\n",
       "      <th>txt_preprocessing</th>\n",
       "      <th>PortStemmer</th>\n",
       "      <th>Lemmatizer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>London</td>\n",
       "      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>menyrbie  phil gahan  chrisitv  and  and</td>\n",
       "      <td>[menyrbie, phil, gahan, chrisitv]</td>\n",
       "      <td>[menyrbi, phil, gahan, chrisitv]</td>\n",
       "      <td>[menyrbie, phil, gahan, chrisitv]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UK</td>\n",
       "      <td>advice Talk to your neighbours family to excha...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>advice talk to your neighbours family to excha...</td>\n",
       "      <td>[advice, talk, neighbours, family, exchange, p...</td>\n",
       "      <td>[advic, talk, neighbour, famili, exchang, phon...</td>\n",
       "      <td>[advice, talk, neighbour, family, exchange, ph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vagabonds</td>\n",
       "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>coronavirus australia  woolworths to give elde...</td>\n",
       "      <td>[coronavirus, australia, woolworths, give, eld...</td>\n",
       "      <td>[coronaviru, australia, woolworth, give, elder...</td>\n",
       "      <td>[coronavirus, australia, woolworth, give, elde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>My food stock is not the only one which is emp...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>my food stock is not the only one which is emp...</td>\n",
       "      <td>[food, stock, one, empty, please, panic, enoug...</td>\n",
       "      <td>[food, stock, one, empti, pleas, panic, enough...</td>\n",
       "      <td>[food, stock, one, empty, please, panic, enoug...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Me, ready to go at supermarket during the #COV...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "      <td>me  ready to go at supermarket during the  cov...</td>\n",
       "      <td>[ready, go, supermarket, covid19, outbreak, pa...</td>\n",
       "      <td>[readi, go, supermarket, covid19, outbreak, pa...</td>\n",
       "      <td>[ready, go, supermarket, covid19, outbreak, pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41152</th>\n",
       "      <td>Wellington City, New Zealand</td>\n",
       "      <td>Airline pilots offering to stock supermarket s...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>airline pilots offering to stock supermarket s...</td>\n",
       "      <td>[airline, pilots, offering, stock, supermarket...</td>\n",
       "      <td>[airlin, pilot, offer, stock, supermarket, she...</td>\n",
       "      <td>[airline, pilot, offering, stock, supermarket,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41153</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Response to complaint not provided citing COVI...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "      <td>response to complaint not provided citing covi...</td>\n",
       "      <td>[response, complaint, provided, citing, covid,...</td>\n",
       "      <td>[respons, complaint, provid, cite, covid, 19, ...</td>\n",
       "      <td>[response, complaint, provided, citing, covid,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41154</th>\n",
       "      <td>NaN</td>\n",
       "      <td>You know itÂs getting tough when @KameronWild...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>you know it  s getting tough when  kameronwild...</td>\n",
       "      <td>[know, getting, tough, kameronwilds, rationing...</td>\n",
       "      <td>[know, get, tough, kameronwild, ration, toilet...</td>\n",
       "      <td>[know, getting, tough, kameronwilds, rationing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41155</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Is it wrong that the smell of hand sanitizer i...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>is it wrong that the smell of hand sanitizer i...</td>\n",
       "      <td>[wrong, smell, hand, sanitizer, starting, turn...</td>\n",
       "      <td>[wrong, smell, hand, sanit, start, turn, coron...</td>\n",
       "      <td>[wrong, smell, hand, sanitizer, starting, turn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41156</th>\n",
       "      <td>i love you so much || he/him</td>\n",
       "      <td>@TartiiCat Well new/used Rift S are going for ...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>tartiicat well new used rift s are going for  ...</td>\n",
       "      <td>[tartiicat, well, new, used, rift, going, 700,...</td>\n",
       "      <td>[tartiicat, well, new, use, rift, go, 700, 00,...</td>\n",
       "      <td>[tartiicat, well, new, used, rift, going, 700,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41157 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           location  \\\n",
       "0                            London   \n",
       "1                                UK   \n",
       "2                         Vagabonds   \n",
       "3                               NaN   \n",
       "4                               NaN   \n",
       "...                             ...   \n",
       "41152  Wellington City, New Zealand   \n",
       "41153                           NaN   \n",
       "41154                           NaN   \n",
       "41155                           NaN   \n",
       "41156  i love you so much || he/him   \n",
       "\n",
       "                                           originaltweet           sentiment  \\\n",
       "0      @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...             Neutral   \n",
       "1      advice Talk to your neighbours family to excha...            Positive   \n",
       "2      Coronavirus Australia: Woolworths to give elde...            Positive   \n",
       "3      My food stock is not the only one which is emp...            Positive   \n",
       "4      Me, ready to go at supermarket during the #COV...  Extremely Negative   \n",
       "...                                                  ...                 ...   \n",
       "41152  Airline pilots offering to stock supermarket s...             Neutral   \n",
       "41153  Response to complaint not provided citing COVI...  Extremely Negative   \n",
       "41154  You know itÂs getting tough when @KameronWild...            Positive   \n",
       "41155  Is it wrong that the smell of hand sanitizer i...             Neutral   \n",
       "41156  @TartiiCat Well new/used Rift S are going for ...            Negative   \n",
       "\n",
       "                                                  corpus  \\\n",
       "0               menyrbie  phil gahan  chrisitv  and  and   \n",
       "1      advice talk to your neighbours family to excha...   \n",
       "2      coronavirus australia  woolworths to give elde...   \n",
       "3      my food stock is not the only one which is emp...   \n",
       "4      me  ready to go at supermarket during the  cov...   \n",
       "...                                                  ...   \n",
       "41152  airline pilots offering to stock supermarket s...   \n",
       "41153  response to complaint not provided citing covi...   \n",
       "41154  you know it  s getting tough when  kameronwild...   \n",
       "41155  is it wrong that the smell of hand sanitizer i...   \n",
       "41156  tartiicat well new used rift s are going for  ...   \n",
       "\n",
       "                                       txt_preprocessing  \\\n",
       "0                      [menyrbie, phil, gahan, chrisitv]   \n",
       "1      [advice, talk, neighbours, family, exchange, p...   \n",
       "2      [coronavirus, australia, woolworths, give, eld...   \n",
       "3      [food, stock, one, empty, please, panic, enoug...   \n",
       "4      [ready, go, supermarket, covid19, outbreak, pa...   \n",
       "...                                                  ...   \n",
       "41152  [airline, pilots, offering, stock, supermarket...   \n",
       "41153  [response, complaint, provided, citing, covid,...   \n",
       "41154  [know, getting, tough, kameronwilds, rationing...   \n",
       "41155  [wrong, smell, hand, sanitizer, starting, turn...   \n",
       "41156  [tartiicat, well, new, used, rift, going, 700,...   \n",
       "\n",
       "                                             PortStemmer  \\\n",
       "0                       [menyrbi, phil, gahan, chrisitv]   \n",
       "1      [advic, talk, neighbour, famili, exchang, phon...   \n",
       "2      [coronaviru, australia, woolworth, give, elder...   \n",
       "3      [food, stock, one, empti, pleas, panic, enough...   \n",
       "4      [readi, go, supermarket, covid19, outbreak, pa...   \n",
       "...                                                  ...   \n",
       "41152  [airlin, pilot, offer, stock, supermarket, she...   \n",
       "41153  [respons, complaint, provid, cite, covid, 19, ...   \n",
       "41154  [know, get, tough, kameronwild, ration, toilet...   \n",
       "41155  [wrong, smell, hand, sanit, start, turn, coron...   \n",
       "41156  [tartiicat, well, new, use, rift, go, 700, 00,...   \n",
       "\n",
       "                                              Lemmatizer  \n",
       "0                      [menyrbie, phil, gahan, chrisitv]  \n",
       "1      [advice, talk, neighbour, family, exchange, ph...  \n",
       "2      [coronavirus, australia, woolworth, give, elde...  \n",
       "3      [food, stock, one, empty, please, panic, enoug...  \n",
       "4      [ready, go, supermarket, covid19, outbreak, pa...  \n",
       "...                                                  ...  \n",
       "41152  [airline, pilot, offering, stock, supermarket,...  \n",
       "41153  [response, complaint, provided, citing, covid,...  \n",
       "41154  [know, getting, tough, kameronwilds, rationing...  \n",
       "41155  [wrong, smell, hand, sanitizer, starting, turn...  \n",
       "41156  [tartiicat, well, new, used, rift, going, 700,...  \n",
       "\n",
       "[41157 rows x 7 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0ae9d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
